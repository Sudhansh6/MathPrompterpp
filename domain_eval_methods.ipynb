{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard imports\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import importlib\n",
    "from functools import partial\n",
    "import csv\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s/miniforge3/envs/llms/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'llm_inference.llm_factory' from '/Users/s/Desktop/Academics/Quarter 4/CSE256/Project/FinalCode/llm_inference/llm_factory.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method imports\n",
    "sys.path.append('..')\n",
    "\n",
    "from methods.mathprompterpp import mathprompterpp\n",
    "from methods.mathprompter import mathprompter\n",
    "from methods.zeroshotCoT import zeroshotCoT\n",
    "from utils.method_utils import generating_algebraic_template\n",
    "from utils.plot_utils import compute_detailed_metrics, plot_individual_metrics\n",
    "from llm_inference.llm_factory import get_llm_service\n",
    "\n",
    "import methods.mathprompterpp\n",
    "import methods.mathprompter\n",
    "import methods.zeroshotCoT\n",
    "import utils.method_utils\n",
    "import llm_inference.llm_factory\n",
    "\n",
    "importlib.reload(methods.mathprompterpp)\n",
    "importlib.reload(methods.zeroshotCoT)   \n",
    "importlib.reload(utils.method_utils)\n",
    "importlib.reload(llm_inference.llm_factory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "suffix = str(random.randint(1, 1000000))\n",
    "random.seed(42)\n",
    "model_service = 'openai'\n",
    "model_name = 'gpt-4o-mini'\n",
    "data_size = 85\n",
    "max_tokens = 200\n",
    "few_shot = True\n",
    "consensus_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and data\n",
    "SERVICE = get_llm_service(model_service, model_name, temperature=0.0, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the methods you want to evaluate\n",
    "run_methods = [\"MathPrompter\", \"MathPrompter++\", \"Zeroshot CoT\"]  # Example methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484748_domain_gpt-4o-mini_85_few_shot\n"
     ]
    }
   ],
   "source": [
    "with open('data/domain.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "data = random.sample(data, k=data_size)  # Take a random sample of 100 rows\n",
    "\n",
    "suffix += \"_domain_\" + model_name.split(\"/\")[-1] + \"_\" + str(data_size) \n",
    "suffix += \"_few_shot\" if few_shot else \"\"\n",
    "print(suffix)\n",
    "\n",
    "# Create folder if not exists\n",
    "if not os.path.exists('results/' + suffix):\n",
    "    os.makedirs('results/' + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MathPrompter\" in run_methods:\n",
    "    # MathPrompter\n",
    "    header_mathprompter = [\"Question\", \"Type\", \"Correct Answer\", \"Predicted Answer\", \"Predicted Algebraic Answer\", \"Predicted Python Answer\", \"Generated Algebraic Template\", \"Generated Expression\", \"Generated Python Code\", \"Variable Mapping\", \"Error\", \"Error Message\"]\n",
    "    df_mathprompter = pd.DataFrame(columns=header_mathprompter)\n",
    "    csv_file_mathprompter = 'results/' + suffix + '/mathprompter_results.csv'  # CSV file path\n",
    "\n",
    "if \"MathPrompter++\" in run_methods:\n",
    "    # MathPrompter++\n",
    "    header_mathprompterpp = [\"Question\", \"Type\", \"Correct Answer\", \"Predicted Answer\", \"Predicted Algebraic Answer\", \"Predicted Python Answer\", \"Generated Algebraic Template\", \"Rough Solution\", \"Generated Expression\", \"Generated Python Code\", \"Variable Mapping\", \"Error\", \"Error Message\"]\n",
    "    df_mathprompterpp = pd.DataFrame(columns=header_mathprompterpp)\n",
    "    csv_file_mathprompterpp = 'results/' + suffix + '/mathprompterpp_results.csv'  # CSV file path\n",
    "\n",
    "if \"Zeroshot CoT\" in run_methods:\n",
    "    # Zeroshot CoT\n",
    "    header_zeroshot_cot = [\"Question\", \"Type\", \"Correct Answer\", \"Predicted Answer\", \"Response\", \"Error\", \"Error Message\"]\n",
    "    df_zeroshot_cot = pd.DataFrame(columns=header_zeroshot_cot)\n",
    "    csv_file_zeroshot_cot = 'results/' + suffix + '/zeroshot_cot_results.csv'  # CSV file path\n",
    "\n",
    "# Example of saving the DataFrames to CSV files\n",
    "if \"MathPrompter\" in run_methods:\n",
    "    df_mathprompter.to_csv(csv_file_mathprompter, index=False)\n",
    "\n",
    "if \"MathPrompter++\" in run_methods:\n",
    "    df_mathprompterpp.to_csv(csv_file_mathprompterpp, index=False)\n",
    "\n",
    "if \"Zeroshot CoT\" in run_methods:\n",
    "    df_zeroshot_cot.to_csv(csv_file_zeroshot_cot, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_csv_files():\n",
    "    if \"MathPrompter\" in run_methods:\n",
    "        with open(csv_file_mathprompter, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header_mathprompter)\n",
    "    if \"MathPrompter++\" in run_methods:\n",
    "        with open(csv_file_mathprompterpp, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header_mathprompterpp)\n",
    "    if \"Zeroshot CoT\" in run_methods:\n",
    "        with open(csv_file_zeroshot_cot, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header_zeroshot_cot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize across different data rows using joblib\n",
    "def process_question(item, debug = False):\n",
    "    question = item[\"Body\"] + \" \" + item[\"Question\"]\n",
    "    correct_answer = item[\"Answer\"]\n",
    "    question_type = item[\"Type\"]\n",
    "    qt, variable_mapping = generating_algebraic_template(question) \n",
    "    if \"MathPrompter\" in run_methods:   \n",
    "        mathprompter_answer = mathprompter(qt, variable_mapping, SERVICE, k = consensus_k, few_shot=few_shot)\n",
    "\n",
    "        # Create a dictionary for the new row\n",
    "        new_row = {\n",
    "            \"Question\": question,\n",
    "            \"Type\": question_type,\n",
    "            \"Correct Answer\": correct_answer,\n",
    "            \"Predicted Answer\": mathprompter_answer[\"Result\"],\n",
    "            \"Predicted Algebraic Answer\": mathprompter_answer[\"Expression_Result\"],\n",
    "            \"Predicted Python Answer\": mathprompter_answer[\"Code_Result\"],\n",
    "            \"Generated Algebraic Template\": qt,\n",
    "            \"Generated Expression\": mathprompter_answer[\"Expression\"],\n",
    "            \"Generated Python Code\": mathprompter_answer[\"Code\"],\n",
    "            \"Variable Mapping\": variable_mapping,\n",
    "            \"Error\": mathprompter_answer[\"Error\"],\n",
    "            \"Error Message\": mathprompter_answer[\"Error_Message\"]\n",
    "        }\n",
    "        if debug:\n",
    "            print(\"MathPrompter\")\n",
    "            print(mathprompter_answer)\n",
    "            print(new_row)\n",
    "        # Append the new row to the DataFrame using pd.concat\n",
    "        # df_mathprompter = pd.concat([df_mathprompter, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # Write to csv\n",
    "        with open(csv_file_mathprompter, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(new_row.values())\n",
    "    if \"MathPrompter++\" in run_methods:\n",
    "        mathprompterpp_answer = mathprompterpp(question, qt, variable_mapping, SERVICE, k = consensus_k, few_shot=few_shot)\n",
    "        \n",
    "        # Create a dictionary for the new row\n",
    "        new_row = {\n",
    "            \"Question\": question,\n",
    "            \"Type\": question_type,\n",
    "            \"Correct Answer\": correct_answer,\n",
    "            \"Predicted Answer\": mathprompterpp_answer[\"Result\"],\n",
    "            \"Predicted Algebraic Answer\": mathprompterpp_answer[\"Expression_Result\"],\n",
    "            \"Predicted Python Answer\": mathprompterpp_answer[\"Code_Result\"],\n",
    "            \"Generated Algebraic Template\": qt,\n",
    "            \"Rough Solution\": mathprompterpp_answer[\"Rough_Solution\"],\n",
    "            \"Generated Expression\": mathprompterpp_answer[\"Expression\"],\n",
    "            \"Generated Python Code\": mathprompterpp_answer[\"Code\"],\n",
    "            \"Variable Mapping\": variable_mapping,\n",
    "            \"Error\": mathprompterpp_answer[\"Error\"],\n",
    "            \"Error Message\": mathprompterpp_answer[\"Error_Message\"]\n",
    "        }\n",
    "        if debug:\n",
    "            print(\"MathPrompter++\")\n",
    "            print(mathprompterpp_answer)\n",
    "            print(new_row)\n",
    "        # Append the new row to the DataFrame using pd.concat\n",
    "        # df_mathprompterpp = pd.concat([df_mathprompterpp, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # Write to csv\n",
    "        with open(csv_file_mathprompterpp, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(new_row.values())\n",
    "    if \"Zeroshot CoT\" in run_methods:\n",
    "        zeroshot_cot_answer = zeroshotCoT(question, SERVICE, max_tokens)    \n",
    "\n",
    "        # Create a dictionary for the new row\n",
    "        new_row = {\n",
    "            \"Question\": question,\n",
    "            \"Type\": question_type,\n",
    "            \"Correct Answer\": correct_answer,\n",
    "            \"Predicted Answer\": zeroshot_cot_answer[\"Answer\"],\n",
    "            \"Response\": zeroshot_cot_answer[\"Response\"],\n",
    "            \"Error\": zeroshot_cot_answer[\"Error\"],\n",
    "            \"Error Message\": zeroshot_cot_answer[\"Error_Message\"]\n",
    "        }\n",
    "        if debug:\n",
    "            print(\"Zeroshot CoT\")\n",
    "            print(zeroshot_cot_answer)\n",
    "            print(new_row)\n",
    "        # Append the new row to the DataFrame using pd.concat\n",
    "        # df_zeroshot_cot = pd.concat([df_zeroshot_cot, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # Write to csv\n",
    "        with open(csv_file_zeroshot_cot, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(new_row.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 9/85 [00:37<05:09,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 13/85 [00:57<05:44,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: int too large to convert to float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 19/85 [01:24<05:13,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 21/85 [02:16<14:39, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'tuple'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 22/85 [02:21<11:38, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'tuple'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 23/85 [02:28<10:04,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 26/85 [03:56<28:31, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: float division by zero\n",
      "An error occurred during the verification process: 'Code_Result'\n",
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 27/85 [04:01<21:03, 21.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 29/85 [04:11<12:25, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 40/85 [05:06<03:32,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 43/85 [05:29<04:57,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 44/85 [05:33<04:10,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 53/85 [06:10<02:17,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 59/85 [32:01<2:02:10, 281.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n",
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 60/85 [32:04<1:22:41, 198.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 61/85 [32:08<55:58, 139.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax error in the expression: invalid syntax (<string>, line 1)\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 62/85 [32:11<37:56, 98.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: float division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 63/85 [32:14<25:44, 70.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 68/85 [32:36<04:30, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 73/85 [33:02<01:35,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 74/85 [33:06<01:13,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime error during expression evaluation: 'NoneType' object is not subscriptable\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 76/85 [33:13<00:46,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax error in the expression: invalid syntax (<string>, line 1)\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 79/85 [33:24<00:26,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 80/85 [33:29<00:23,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n",
      "Error when executing Python code: solution() got an unexpected keyword argument 'var_A'\n",
      "An error occurred during the verification process: float() argument must be a string or a real number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 81/85 [33:33<00:17,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the verification process: 'Code_Result'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [33:46<00:00, 23.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "reset_csv_files()\n",
    "# if not few_shot:\n",
    "run_methods = [\"MathPrompter\", \"MathPrompter++\"]\n",
    "for i in tqdm(range(85)):\n",
    "    # print(data[i])\n",
    "    process_question(data[i], debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1598447969.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Run the parallelized function\n",
    "return\n",
    "reset_csv_files()\n",
    "process_question_partial = partial(process_question, debug=False)\n",
    "Parallel(n_jobs=2)(delayed(process_question_partial)(item) for item in tqdm(data[:1], desc=\"Processing Questions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathPrompter\n",
      "defaultdict(<function mathprompter.<locals>.<lambda> at 0x3081bb2e0>, {'Expression': 'var_A + var_B', 'Code': 'def solution(var_A, var_B):\\n    return var_A + var_B', 'Result': 91, 'Results': {'Expression': [475, 501, 569, 263, 469], 'Code': [475, 501, 569, 263, 469], 'Test_Input': [{'var_A': 165, 'var_B': 310}, {'var_A': 244, 'var_B': 257}, {'var_A': 78, 'var_B': 491}, {'var_A': 32, 'var_B': 231}, {'var_A': 53, 'var_B': 416}]}, 'Expression_Result': 91.0, 'Code_Result': 91.0, 'Error': False, 'Error_Message': ''})\n",
      "{'Question': 'Danny collects bottle caps. He lost 66 bottle caps at the park. Now he has 25 bottle caps in his collection. How many bottle caps did danny have at first?', 'Type': 'Addition', 'Correct Answer': 91.0, 'Predicted Answer': 91, 'Predicted Algebraic Answer': 91.0, 'Predicted Python Answer': 91.0, 'Generated Algebraic Template': 'Danny collects bottle caps. He lost var_A bottle caps at the park. Now he has var_B bottle caps in his collection. How many bottle caps did danny have at first?', 'Generated Expression': 'var_A + var_B', 'Generated Python Code': 'def solution(var_A, var_B):\\n    return var_A + var_B', 'Variable Mapping': {'var_A': 66.0, 'var_B': 25.0}, 'Error': False, 'Error Message': ''}\n",
      "MathPrompter++\n",
      "defaultdict(<function mathprompterpp.<locals>.<lambda> at 0x3081bb130>, {'Rough_Solution': '1. Start with the number of bottle caps Danny has now (25).\\n2. Add the number of bottle caps he lost (66) to the current amount to find out how many he had initially.', 'Expression': 'var_A + var_B', 'Code': 'def solution(var_A, var_B):\\n    return var_A + var_B', 'Result': 91, 'Expression_Result': 91.0, 'Code_Result': 91.0, 'Error': False, 'Error_Message': ''})\n",
      "{'Question': 'Danny collects bottle caps. He lost 66 bottle caps at the park. Now he has 25 bottle caps in his collection. How many bottle caps did danny have at first?', 'Type': 'Addition', 'Correct Answer': 91.0, 'Predicted Answer': 91, 'Predicted Algebraic Answer': 91.0, 'Predicted Python Answer': 91.0, 'Generated Algebraic Template': 'Danny collects bottle caps. He lost var_A bottle caps at the park. Now he has var_B bottle caps in his collection. How many bottle caps did danny have at first?', 'Rough Solution': '1. Start with the number of bottle caps Danny has now (25).\\n2. Add the number of bottle caps he lost (66) to the current amount to find out how many he had initially.', 'Generated Expression': 'var_A + var_B', 'Generated Python Code': 'def solution(var_A, var_B):\\n    return var_A + var_B', 'Variable Mapping': {'var_A': 66.0, 'var_B': 25.0}, 'Error': False, 'Error Message': ''}\n",
      "Zeroshot CoT\n",
      "defaultdict(<function zeroshotCoT.<locals>.<lambda> at 0x3081b8820>, {'Error': False, 'Error_Message': '', 'Response': 'To find out how many bottle caps Danny had at first, we can set up the problem using a simple equation.\\n\\n1. Let \\\\( x \\\\) be the number of bottle caps Danny had at first.\\n2. According to the problem, Danny lost 66 bottle caps. So, after losing them, he has \\\\( x - 66 \\\\) bottle caps.\\n3. We know that after losing the bottle caps, he has 25 bottle caps left.\\n\\nNow we can set up the equation:\\n\\n\\\\[\\nx - 66 = 25\\n\\\\]\\n\\n4. To solve for \\\\( x \\\\), we can add 66 to both sides of the equation:\\n\\n\\\\[\\nx - 66 + 66 = 25 + 66\\n\\\\]\\n\\nThis simplifies to:\\n\\n\\\\[\\nx = 91\\n\\\\]\\n\\nSo, Danny had **91 bottle caps** at first.91', 'Answer': 91.0})\n",
      "{'Question': 'Danny collects bottle caps. He lost 66 bottle caps at the park. Now he has 25 bottle caps in his collection. How many bottle caps did danny have at first?', 'Type': 'Addition', 'Correct Answer': 91.0, 'Predicted Answer': 91.0, 'Response': 'To find out how many bottle caps Danny had at first, we can set up the problem using a simple equation.\\n\\n1. Let \\\\( x \\\\) be the number of bottle caps Danny had at first.\\n2. According to the problem, Danny lost 66 bottle caps. So, after losing them, he has \\\\( x - 66 \\\\) bottle caps.\\n3. We know that after losing the bottle caps, he has 25 bottle caps left.\\n\\nNow we can set up the equation:\\n\\n\\\\[\\nx - 66 = 25\\n\\\\]\\n\\n4. To solve for \\\\( x \\\\), we can add 66 to both sides of the equation:\\n\\n\\\\[\\nx - 66 + 66 = 25 + 66\\n\\\\]\\n\\nThis simplifies to:\\n\\n\\\\[\\nx = 91\\n\\\\]\\n\\nSo, Danny had **91 bottle caps** at first.91', 'Error': False, 'Error Message': ''}\n"
     ]
    }
   ],
   "source": [
    "process_question(data[0], debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
